{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instagram Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadhuzaifa/Instagram-scraper/blob/master/Instagram_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYMMeD7PBXIR",
        "colab_type": "text"
      },
      "source": [
        "#Instagram Public Post Scraper\n",
        "Instagram-scraper is an application written in Python3 that scrapes and downloads instagram posts for puv Use responsibly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExHm2Lg2BjxZ",
        "colab_type": "text"
      },
      "source": [
        "##Necessary Libraries\n",
        "This program was written in the language Python3 on Google Colab. Make sure the following are available for the program to run properly:\n",
        "- Selenium (3.141.0+)\n",
        "- chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCTxXxmmyVi2",
        "colab_type": "code",
        "outputId": "3f59fecf-efba-4934-f431-fadb7a873492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install selenium\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "import sys\n",
        "import time \n",
        "import selenium \n",
        "\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "print(\"selenium Version = \", selenium.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,784 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [35.2 kB]\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,622 B]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [861 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,362 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [832 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [48.7 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,155 kB]\n",
            "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [861 kB]\n",
            "Fetched 7,210 kB in 3s (2,457 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 74.4 MB of archives.\n",
            "After this operation, 264 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 80.0.3987.87-0ubuntu0.18.04.1 [1,095 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 80.0.3987.87-0ubuntu0.18.04.1 [66.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 80.0.3987.87-0ubuntu0.18.04.1 [3,155 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 80.0.3987.87-0ubuntu0.18.04.1 [4,044 kB]\n",
            "Fetched 74.4 MB in 3s (24.0 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 133872 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_80.0.3987.87-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_80.0.3987.87-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_80.0.3987.87-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_80.0.3987.87-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (80.0.3987.87-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "selenium Version =  3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w00dkB5TyXf4",
        "colab_type": "code",
        "outputId": "37be6939-d176-4428-b50b-522d997d17a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "hashtag='food'\n",
        "# browser.get('https://www.instagram.com/explore/tags/'+hashtag)\n",
        "Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVbtcusFCctP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import csv\n",
        "import re\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2GypIMw3VAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InstagramBot():\n",
        "    def __init__(self):\n",
        "      self.chrome_options = webdriver.ChromeOptions()\n",
        "      self.browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "      self.csvScrapedData = [[\"description\", \"weight\", \"location\", \"user\", \"time\", \"image\"]]\n",
        "      self.hashtag = \"\"\n",
        "      \n",
        "    def signIn(self, email, password):\n",
        "      print(\"Signing In\")\n",
        "      self.email = email\n",
        "      self.password = password\n",
        "      self.browser.get('https://www.instagram.com/accounts/login/')\n",
        "      emailInput = self.browser.find_elements_by_css_selector('form input')[0]\n",
        "      passwordInput = self.browser.find_elements_by_css_selector('form input')[1]\n",
        "      emailInput.send_keys(self.email)\n",
        "      passwordInput.send_keys(self.password)\n",
        "      passwordInput.send_keys(Keys.ENTER)\n",
        "      time.sleep(2)\n",
        "    \n",
        "    def scrape(self, url):\n",
        "      self.browser.get(url)\n",
        "      self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "      elements = self.browser.find_elements_by_xpath(\"//div[@class='v1Nh3 kIKUG  _bz0w']\")\n",
        "      hrefElements = self.browser.find_elements_by_xpath(\"//div[@class='v1Nh3 kIKUG  _bz0w']/a\")\n",
        "      elements_link = [x.get_attribute(\"href\") for x in hrefElements]\n",
        "      for elements in elements_link:\n",
        "        self.scrapePost(elements)\n",
        " \n",
        "    def scrapePost(self, url):\n",
        "      self.browser.get(url)\n",
        "      print(\"Scraping Post: \" + url)\n",
        "      try: \n",
        "        location_element = self.browser.find_element_by_xpath(\"//a[@class='O4GlU']\").text\n",
        "        location_element = location_element.replace(\",\", \" \")\n",
        "        user_element = self.browser.find_element_by_xpath(\"//a[@class='FPmhX notranslate nJAzx']\")\n",
        "        user_element_text = user_element.text\n",
        "        user_element_text = user_element_text.replace(\",\", \" \")\n",
        "        user_element_link = user_element.get_attribute(\"href\")\n",
        "        try:\n",
        "          desc_element = self.browser.find_element_by_xpath(\"//div[@class='C4VMK']/span\")\n",
        "          desc_text = desc_element.text\n",
        "          desc_text = desc_text.replace(\"\\n\", \" \")\n",
        "          desc_text = desc_text.replace(\",\", \" \")\n",
        "        except:\n",
        "          desc_text = \" \"\n",
        "          pass\n",
        "        try: \n",
        "          timestamp_element = self.browser.find_element_by_xpath(\"//div[@class='k_Q0X NnvRN']/a/time\")\n",
        "          timestamp = timestamp_element.get_attribute(\"datetime\")\n",
        "          timestamp = timestamp.replace(\"\\n\", \" \")\n",
        "          timestamp = timestamp.replace(\",\", \" \")\n",
        "        except:\n",
        "          timestamp = \" \"\n",
        "          pass    \n",
        "        try:\n",
        "          likes_element = self.browser.find_element_by_xpath(\"//a[@class='zV_Nj']/span\").text\n",
        "          likes_element = likes_element.replace(\",\", \"\")\n",
        "          no_of_likes = int(likes_element)\n",
        "          followerCount = self.findFollowerCount(user_element_link)\n",
        "          weight = no_of_likes/followerCount\n",
        "        except:\n",
        "          weight = 0\n",
        "          pass\n",
        "        image_url = self.findImage()\n",
        "        self.scrapedData = [desc_text, weight ,location_element, user_element_text, timestamp, image_url]\n",
        "        print(self.scrapedData)\n",
        "        self.csvScrapedData.append(self.scrapedData)\n",
        "      except:\n",
        "        pass\n",
        "      \n",
        "       \n",
        "    def findImage(self):\n",
        "      image_element = self.browser.find_element_by_xpath(\"//div[@class='KL4Bh']/img\")\n",
        "      image_element_link = image_element.get_attribute(\"src\")\n",
        "      return image_element_link\n",
        "\n",
        "   \n",
        "    def findFollowerCount(self, userURL):\n",
        "      self.browser.get(userURL)\n",
        "      followers_count_int = 0 \n",
        "      try:\n",
        "        count_element = self.browser.find_elements_by_xpath(\"//span[@class='g47SY ']\")\n",
        "        followers_count = count_element[1].get_attribute(\"title\")\n",
        "        followers_count = followers_count.replace(\",\", \"\")\n",
        "        followers_count_int = int(followers_count)\n",
        "      except:\n",
        "          pass    \n",
        "      return followers_count_int\n",
        "    \n",
        "    \n",
        "    def scrapeWithHashtags(self, hashtags):\n",
        "      for hashtag in hashtags:\n",
        "        self.hashtag = hashtag\n",
        "        print(\"-----------Scraping the hashtag '\" + hashtag +\"' -----------\")\n",
        "        url = 'https://www.instagram.com/explore/tags/' + hashtag\n",
        "        self.scrape(url)\n",
        "        \n",
        "    def exportCSVFile(self):\n",
        "      csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
        "      with open('csvScrapedData.csv', 'w') as f:\n",
        "        writer = csv.writer(f, dialect='myDialect')\n",
        "        for row in self.csvScrapedData:\n",
        "          writer.writerow(row)\n",
        "      f.close()\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxQ3i-0llcDd",
        "colab_type": "code",
        "outputId": "e3628f92-273e-4137-b569-5e69e64e6530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "scrape_type = input(\"Do you want to scrape any private posts [y/n]:\\n\")\n",
        "hashtags = ['dog']\n",
        "bot = InstagramBot()\n",
        "\n",
        "if scrape_type == \"y\":\n",
        "  username = input(\"What's your email?\\n\")\n",
        "  password = input(\"What's your password?\\n\")\n",
        "  bot.signIn(username, password)\n",
        "elif scrape_type == \"n\":\n",
        "  pass\n",
        "else:\n",
        "  sys.exit(\"No valid Input\")\n",
        "\n",
        "bot.scrapeWithHashtags(hashtags)\n",
        "bot.exportCSVFile()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Do you want to scrape any private posts [y/n]:\n",
            "n\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: use options instead of chrome_options\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------Scraping the hashtag 'dog' -----------\n",
            "Scraping Post: https://www.instagram.com/p/B-IWBGogh2n/\n",
            "Scraping Post: https://www.instagram.com/p/B-ISb8wH66B/\n",
            "Scraping Post: https://www.instagram.com/p/B-IKe04BHrA/\n",
            "Scraping Post: https://www.instagram.com/p/B-IQ24eH9uX/\n",
            "Scraping Post: https://www.instagram.com/p/B-IPr7GgTQU/\n",
            "Scraping Post: https://www.instagram.com/p/B-IZVPMh_2g/\n",
            "Scraping Post: https://www.instagram.com/p/B-INGOCJCXw/\n",
            "Scraping Post: https://www.instagram.com/p/B-IPIBkDR72/\n",
            "Scraping Post: https://www.instagram.com/p/B-IO2gqpLNo/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgITpjtb0/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgIRjJZ6F/\n",
            "Scraping Post: https://www.instagram.com/p/B-If3ixo-fk/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgHuKnvE-/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgHcrJSP6/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgHU7hUGj/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgHUKIlKL/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgHKnK5nn/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgG-NAblm/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgHCTh0Bx/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgG9ChpE7/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgG20IQv_/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgG3NBN8c/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGtsjMa0/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGmkj8Bs/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGkxprpx/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGjEJcZ1/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGd6jxMv/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGa8hZjB/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGWYBhfk/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGP8h2wC/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGNFJHW-/\n",
            "Scraping Post: https://www.instagram.com/p/B-If9ONDtx6/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgGBlJJg0/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgF_-JzEY/\n",
            "Scraping Post: https://www.instagram.com/p/B-IfxdFg4QW/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgF9Jn5_e/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgF6bA_0a/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgF3zJ7_0/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgFr1pXPZ/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgFkaoPWo/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgFlJo6RU/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgFiGhDJ9/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgFh4JBOj/\n",
            "Scraping Post: https://www.instagram.com/p/B-IgFdUFoEQ/\n",
            "Scraping Post: https://www.instagram.com/p/B-If9OslZWn/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}